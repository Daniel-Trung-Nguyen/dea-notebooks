{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream gauge/pixel correlations <img align=\"right\" src=\"../../../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatibility:** Notebook currently compatible with both the NCI and DEA Sandbox environments. \n",
    "* **Products used:** \n",
    "[ga_ls7e_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls5t_ard_3),\n",
    "[ga_ls7e_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls7e_ard_3),\n",
    "[ga_ls7e_ard_3](https://explorer.sandbox.dea.ga.gov.au/ga_ls8c_ard_3)\n",
    "\n",
    "## Description\n",
    "\n",
    "Understanding the movement of floodwater throughout the landscape is critical to managing and tracking water in our important river basins. Tracking floodwater is hard though as satellite data are not always available and the flow of water through the landscape can be very complicated. It would be really nice if we could use stream gauges as a proxy for floodwater levels away from the streams they probe. Stream gauge data are readily available for many rivers and streams throughout the continent, and the data are well-sampled and reliable. This notebook estimates the linear correlation between Tasseled-Cap Wetness at a location and the height of nearby stream gauges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the analysis parameters and then run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datacube\n",
    "from tqdm.auto import tqdm\n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "import scipy.stats\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"../Scripts\")\n",
    "import dea_bom\n",
    "import dea_bandindices\n",
    "import dea_datahandling\n",
    "\n",
    "dc = datacube.Datacube(app=\"StreamPixelRelationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "Specify a region to analyse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Murray @ Colignan\n",
    "southwest = -34.58, 142.39\n",
    "northeast = -34.55, 142.43\n",
    "\n",
    "# Murray @ Gulpa\n",
    "# southwest = -35.87, 144.96\n",
    "# northeast = -35.84, 145.03\n",
    "\n",
    "ylim, xlim = zip(southwest, northeast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the BOM\n",
    "\n",
    "The Bureau of Meteorology keeps stream gauge data. Get all stream gauge stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = dea_bom.get_stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert stations, 'No stations retrieved from BOM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then find all the stations in our analysis region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_in_range = [\n",
    "    s\n",
    "    for s in stations\n",
    "    if s.pos and ylim[0] <= s.pos[0] <= ylim[1] and xlim[0] <= s.pos[1] <= xlim[1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 stations in range\n"
     ]
    }
   ],
   "source": [
    "print('Found', len(stations_in_range), f'station{\"s\" if len(stations_in_range) != 1 else \"\"} in range')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get stream data for each station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = [dea_bom.get_station_data(s) for s in stations_in_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out stations without any data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_in_range = [s for d, s in zip(station_data, stations_in_range) if len(d.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 station with data\n"
     ]
    }
   ],
   "source": [
    "print('Found', len(stations_in_range), f'station{\"s\" if len(stations_in_range) != 1 else \"\"} with data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = [d for d in station_data if len(d.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then interpolate each gauge to daily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = [d.resample(\"1D\").mean() for d in station_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most recent first observation amongst all stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = max(d.index.min() for d in station_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then crop every data series to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = [d[d.index >= latest] for d in station_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all stations have data over the same time range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TCW data for this region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasselled-Cap Wetness (TCW) is good at detecting water when mixed with vegetation, and we expect wet vegetation on floodplains.\n",
    "\n",
    "Load Landsat data so we can calculate TCW. Downsample to 100m: we don't need fine details if we're analysing entire floodplains, and this dramatically speeds up our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding datasets\n",
      "    ga_ls8c_ard_3\n",
      "    ga_ls5t_ard_3\n",
      "    ga_ls7e_ard_3\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 557 out of 930 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 557 time steps\n"
     ]
    }
   ],
   "source": [
    "ls = dea_datahandling.load_ard(\n",
    "    dc,\n",
    "    products=[\"ga_ls8c_ard_3\", \"ga_ls5t_ard_3\", \"ga_ls7e_ard_3\"],\n",
    "    time=(latest, \"2020-10\"),\n",
    "    min_gooddata=0.8,\n",
    "    x=xlim,\n",
    "    y=ylim,\n",
    "    output_crs=\"EPSG:3577\",\n",
    "    resolution=(-100, 100),\n",
    "    resampling=\"bilinear\",\n",
    "    measurements=[\n",
    "        \"nbart_red\",\n",
    "        \"nbart_blue\",\n",
    "        \"nbart_green\",\n",
    "        \"nbart_nir\",\n",
    "        \"nbart_swir_1\",\n",
    "        \"nbart_swir_2\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then calculate TCW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcw = dea_bandindices.calculate_indices(ls, \"TCW\", \"ga_ls_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcw.TCW.isel(time=101).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindex the stream gauge data to the TCW data\n",
    "\n",
    "Align the stream gauge data with the TCW data by reindexing them so their dates match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data_tcw = []\n",
    "for i in range(len(station_data)):\n",
    "    times = np.sort(np.unique(np.concatenate([tcw.time, station_data[i].index])))\n",
    "    station_data_tcw.append(\n",
    "        station_data[i]\n",
    "        .reindex(times)\n",
    "        .interpolate(method=\"nearest\")\n",
    "        .reindex(tcw.time.values)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the TCW and stream gauge data\n",
    "\n",
    "Prepare the data for correlation estimation.\n",
    "\n",
    "Divide the stream gauges by their maximum values to limit their range from 0 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_features = np.nan_to_num(np.array([d.values[:, 0] for d in station_data_tcw]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_features /= stream_features.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for the TCW data, and also reshape to collapse the spatial axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcw_values = tcw.TCW.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcw_targets = np.nan_to_num(tcw_values.reshape(tcw_values.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tcw_targets.shape[0] == stream_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcw_targets /= abs(tcw_targets).max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression slope between each time series\n",
    "\n",
    "Calculate the linear regression slope between the stream gauge and TCW time series for each gauge and each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations(stream_features, tcw_targets):\n",
    "    slopes = np.zeros((stream_features.shape[1], tcw_targets.shape[1]))\n",
    "    rvalues = np.zeros((stream_features.shape[1], tcw_targets.shape[1]))\n",
    "    for i in range(stream_features.shape[1]):\n",
    "        for pos in range(tcw_targets.shape[1]):\n",
    "            lrr = scipy.stats.linregress(stream_features[:, i], tcw_targets[:, pos])\n",
    "            slopes[i, pos] = lrr.slope\n",
    "            rvalues[i, pos] = lrr.rvalue\n",
    "    return slopes, rvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes, rvalues = get_correlations(stream_features, tcw_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can plot the slopes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_locations = gpd.GeoDataFrame(\n",
    "    geometry=[shapely.geometry.Point(s.pos[::-1]) for s in stations_in_range],\n",
    "    crs=\"EPSG:4326\",\n",
    ").to_crs(tcw.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_station_correlations(values, vmin=0, vmax=1, cmap=\"viridis\"):\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    for i in range(len(station_data)):\n",
    "        plt.subplot(6, 3, i + 1)\n",
    "        plt.pcolormesh(\n",
    "            tcw.x,\n",
    "            tcw.y,\n",
    "            values[i].reshape(tcw.TCW.shape[1:]),\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            cmap=cmap,\n",
    "        )\n",
    "        plt.colorbar()\n",
    "        plt.scatter(\n",
    "            station_locations.iloc[i].geometry.x,\n",
    "            station_locations.iloc[i].geometry.y,\n",
    "            edgecolor=\"k\",\n",
    "            facecolor=\"w\",\n",
    "            s=100,\n",
    "            linewidth=2,\n",
    "        )\n",
    "        plt.axis(\"off\")\n",
    "        plt.scatter(\n",
    "            station_locations.iloc[i].geometry.x,\n",
    "            station_locations.iloc[i].geometry.y,\n",
    "            edgecolor=\"k\",\n",
    "            facecolor=\"w\",\n",
    "            s=100,\n",
    "            linewidth=2,\n",
    "        )\n",
    "        plt.text(\n",
    "            station_locations.iloc[i].geometry.x,\n",
    "            station_locations.iloc[i].geometry.y,\n",
    "            stations_in_range[i].name,\n",
    "            c=\"white\",\n",
    "        )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_station_correlations(abs(slopes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two stream gauges in this region. One is off-stream and one is on-stream. The on-stream gauge is clearly related to the TCW values of the eastern half of the region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly shift the data to estimate how much correlation is coincidental\n",
    "\n",
    "Estimate how much correlation we should expect just by chance if there is no real correlation at all between the time series. To do this, shift the TCW time series so that there should be no correlation. Then repeat the above analysis. The amount of correlation detected is the expected coincidental correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_shifted, rvalues_shifted = get_correlations(\n",
    "    stream_features, np.roll(tcw_targets, 100, axis=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_station_correlations(abs(slopes_shifted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_corr = abs(slopes_shifted).mean(axis=1)\n",
    "\n",
    "print(\"Random correlation:\")\n",
    "for i in range(len(stations_in_range)):\n",
    "    print(stations_in_range[i].name, rand_corr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret this as a noise level and use it to mask insignificant correlations, which we will say are pixels with correlations less than 3 times the noise level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_station_correlations(\n",
    "    np.where(abs(slopes) < 3 * rand_corr[:, None], rand_corr[:, None], abs(slopes))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detected correlations for the on-stream gauge seem significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very simple way of estimating the correlation between stream gauges and the surrounding landscape. Future work should investigate non-linear correlations, potential lag between stream gauges and landscape changes, and merging together identical or near-identical stream gauges (e.g. neighbouring gauges on the same river)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** November 2020\n",
    "\n",
    "**Compatible datacube version:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Tags: :index:`fiona`, :index:`geopandas`, :index:`Geotiff`, :index:`masking`, :index:`rasterio`, :index:`shapefile`, :index:`WOfS`, :index:`WOFL`, :index:`shapely`, :index:`raster to polygons`, :index:`polygons`, :index:`vectorise`, :index:`DEA Waterbodies`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
